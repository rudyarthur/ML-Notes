{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1e78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92fe084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  0.,  2.,  6.,  9., 15.,  9., 10., 12.,  9.,  8.,  4.,  4.,\n",
       "         0.,  4.,  3.,  0.,  0.,  0.,  1.]),\n",
       " array([1.11314892, 1.37185377, 1.63055863, 1.88926348, 2.14796834,\n",
       "        2.4066732 , 2.66537805, 2.92408291, 3.18278776, 3.44149262,\n",
       "        3.70019748, 3.95890233, 4.21760719, 4.47631204, 4.7350169 ,\n",
       "        4.99372176, 5.25242661, 5.51113147, 5.76983632, 6.02854118,\n",
       "        6.28724603]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.normal(loc=3,scale=1,size=100)\n",
    "plt.hist(x, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8421915e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  1.,  6.,  5.,  5.,  5.,  6.,  9., 11., 12.,  6., 10.,  6.,\n",
       "         7.,  2.,  4.,  1.,  0.,  0.,  1.]),\n",
       " array([0.79488547, 0.8162744 , 0.83766333, 0.85905226, 0.88044119,\n",
       "        0.90183012, 0.92321905, 0.94460798, 0.96599691, 0.98738583,\n",
       "        1.00877476, 1.03016369, 1.05155262, 1.07294155, 1.09433048,\n",
       "        1.11571941, 1.13710834, 1.15849726, 1.17988619, 1.20127512,\n",
       "        1.22266405]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMN0lEQVR4nO3dbYyld1nH8e/PFlIrlSI7QWwZti+aaoMlJRNFSaxSTPpAqE8v2lik2GTeKBQCwRKNNfiCNRKjRoGsUBe1KZpaYyM+0JQ2jaFt2G1r6QMPDaxlaXEXq6CQWKqXL+a8WIadOafnvvecuXa/n2Sz52nmvuaf2W/vnnPuc6eqkCT1813LHkCSNB8DLklNGXBJasqAS1JTBlySmjp1kRvbtWtX7d69e5GblKT2Dhw48NWqWtl8+0IDvnv3bvbv37/ITUpSe0n+9Vi3+xSKJDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKamhrwJDcmOZzk4aNu+90kn0nyUJK/SXLmcZ1SkvQdZtkD3wdcsum224FXVNUFwOeAd488lyRpiqkBr6q7gac33fbxqnp2cvVe4OzjMJskaRtjHIn5y8BfbnVnknVgHWB1dXWEzUnHtvv6j839tQf3XD7iJNJiDHoRM8mvA88CN231mKraW1VrVbW2svIdh/JLkuY09x54kmuA1wMXl+dlk6SFmyvgSS4B3gVcVFXfHHckSdIsZnkb4c3APcB5SQ4luRb4I+AM4PYkDyb54HGeU5K0ydQ98Kq66hg3f/g4zCJJeg48ElOSmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmxjihgzSaISdlkE427oFLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1NTXgSW5McjjJw0fd9n1Jbk/y+cnfLzq+Y0qSNptlD3wfcMmm264H7qiqc4E7JtclSQs0NeBVdTfw9KabrwA+Mrn8EeBnxh1LkjTNvCd0eElVPTW5/BXgJVs9MMk6sA6wuro65+aknW3IiSgO7rl8xEl0Mhn8ImZVFVDb3L+3qtaqam1lZWXo5iRJE/MG/N+SvBRg8vfh8UaSJM1i3oDfBrxpcvlNwN+OM44kaVazvI3wZuAe4Lwkh5JcC+wBfjrJ54HXTa5LkhZo6ouYVXXVFnddPPIskqTnwCMxJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJamreEzpIWxpycgNJs3MPXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNDQp4krcneSTJw0luTnLaWINJkrY3d8CTnAW8FVirqlcApwBXjjWYJGl7Q59CORX47iSnAqcDTw4fSZI0i7kDXlVfBt4HPAE8BXytqj6++XFJ1pPsT7L/yJEj808qSfo2Q55CeRFwBXAO8APA9yS5evPjqmpvVa1V1drKysr8k0qSvs2Qp1BeB3yxqo5U1beAW4EfH2csSdI0QwL+BPDqJKcnCXAx8Ng4Y0mSphnyHPh9wC3A/cCnJ99r70hzSZKmOHXIF1fVDcANI80iSXoOPBJTkpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgZ9Foqk5dp9/cfm/tqDey4fcRItg3vgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTQ0KeJIzk9yS5DNJHkvyY2MNJkna3tCPk/0D4B+r6heSPB84fYSZJEkzmDvgSV4I/ARwDUBVPQM8M85YkqRphuyBnwMcAf40ySuBA8B1VfWNox+UZB1YB1hdXR2wueU52T40f8jP29Uyf+aTcb01jiHPgZ8KvAr4QFVdCHwDuH7zg6pqb1WtVdXaysrKgM1Jko42JOCHgENVdd/k+i1sBF2StABzB7yqvgJ8Kcl5k5suBh4dZSpJ0lRD34XyFuCmyTtQvgC8efhIkqRZDAp4VT0IrI0ziiTpufBITElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLU1NBPI9QUnm1F0vHiHrgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTgwOe5JQkDyT5uzEGkiTNZow98OuAx0b4PpKk52BQwJOcDVwOfGiccSRJsxp6QoffB94FnLHVA5KsA+sAq6urAzcnaScYeqKSg3suH2mSk9vce+BJXg8crqoD2z2uqvZW1VpVra2srMy7OUnSJkOeQnkN8IYkB4GPAq9N8hejTCVJmmrugFfVu6vq7KraDVwJfKKqrh5tMknStnwfuCQ1NcpZ6avqLuCuMb6XJGk27oFLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLU1CifhbIIQz5A3g+Pl3Qicg9ckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpqbkDnuRlSe5M8miSR5JcN+ZgkqTtDfk42WeBd1TV/UnOAA4kub2qHh1pNknSNubeA6+qp6rq/snl/wIeA84aazBJ0vZGOaFDkt3AhcB9x7hvHVgHWF1dHWNzkkYw5CQp2hkGv4iZ5AXAXwNvq6qvb76/qvZW1VpVra2srAzdnCRpYlDAkzyPjXjfVFW3jjOSJGkWQ96FEuDDwGNV9XvjjSRJmsWQPfDXAG8EXpvkwcmfy0aaS5I0xdwvYlbVPwMZcRZJ0nPgkZiS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqalRzsiz03nmEWlnGfJv8uCey0ecZHZDO3I85nYPXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqalBAU9ySZLPJnk8yfVjDSVJmm7ugCc5Bfhj4FLgfOCqJOePNZgkaXtD9sB/BHi8qr5QVc8AHwWuGGcsSdI0Q07ocBbwpaOuHwJ+dPODkqwD65Or/53kswO2ebRdwFdH+l4nGtdma67N1lqsTX5nKZsdvDYD5375sW487mfkqaq9wN6xv2+S/VW1Nvb3PRG4Nltzbbbm2mxtp67NkKdQvgy87KjrZ09ukyQtwJCAfwo4N8k5SZ4PXAncNs5YkqRp5n4KpaqeTfKrwD8BpwA3VtUjo0023ehPy5xAXJutuTZbc222tiPXJlW17BkkSXPwSExJasqAS1JTOz7g0w7XT7Ka5M4kDyR5KMlly5hzGWZYm5cnuWOyLnclOXsZcy5akhuTHE7y8Bb3J8kfTtbtoSSvWvSMyzLD2vxgknuS/E+Sdy56vmWbYX1+cfI78+kkn0zyykXPeLQdHfAZD9f/DeCvqupCNt4J8/7FTrkcM67N+4A/q6oLgPcA713slEuzD7hkm/svBc6d/FkHPrCAmXaKfWy/Nk8Db2Xjd+dktI/t1+eLwEVV9cPAb7PkFzd3dMCZ7XD9Ar53cvmFwJMLnG+ZZlmb84FPTC7feYz7T0hVdTcbIdrKFWz8h62q6l7gzCQvXcx0yzVtbarqcFV9CvjW4qbaOWZYn09W1X9Mrt7LxvEvS7PTA36sw/XP2vSY3wKuTnII+HvgLYsZbelmWZt/AX5ucvlngTOSvHgBs+10s6ydNM21wD8sc4CdHvBZXAXsq6qzgcuAP09yIvxcY3gncFGSB4CL2DhS9n+XO5LUX5KfYiPgv7bMOY77Z6EMNMvh+tcyec6qqu5JchobHzxzeCETLs/UtamqJ5nsgSd5AfDzVfWfixpwB/NjIDS3JBcAHwIurap/X+YsO31PdZbD9Z8ALgZI8kPAacCRhU65HFPXJsmuo/5v5N3AjQuecae6DfilybtRXg18raqeWvZQ2vmSrAK3Am+sqs8te54dvQe+1eH6Sd4D7K+q24B3AH+S5O1svKB5TZ0Eh5fOuDY/Cbw3SQF3A7+ytIEXKMnNbPzsuyavjdwAPA+gqj7IxmsllwGPA98E3rycSRdv2tok+X5gPxtvDPi/JG8Dzq+qry9n4sWa4XfnN4EXA+9PAvDsMj+l0EPpJampnf4UiiRpCwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklN/T+TQb9iXcEt9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.random.normal(loc=1,scale=0.1,size=100)\n",
    "plt.hist(y, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267d236",
   "metadata": {},
   "source": [
    "## Problem with R-squared comparisons between models with(out) an intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35e01744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x + 2*y + np.random.normal(0,2,100)\n",
    "X = np.vstack([x,y]).transpose()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb982f",
   "metadata": {},
   "source": [
    "The model here `z = x + 2y` doesn't have an intercept when (x,y) = 0, z = 0. So it should be better to fit it without an intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "382a8472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit with intercept = 0.17862466754810813\n",
      "fit without intercept = 0.874643036379007\n"
     ]
    }
   ],
   "source": [
    "nointercept_model = sm.OLS(z, X).fit()\n",
    "Xc= sm.add_constant(X)  #allows nonzero intercept\n",
    "intercept_model = sm.OLS(z, Xc).fit()\n",
    "print(\"R-squared with intercept =\", intercept_model.rsquared )\n",
    "print(\"R-squared without intercept =\", nointercept_model.rsquared )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f60cc",
   "metadata": {},
   "source": [
    "The difference is massive! But that seems suspicious..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8076bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.179\n",
      "Model:                            OLS   Adj. R-squared:                  0.162\n",
      "Method:                 Least Squares   F-statistic:                     10.55\n",
      "Date:                Mon, 21 Aug 2023   Prob (F-statistic):           7.17e-05\n",
      "Time:                        07:54:23   Log-Likelihood:                -210.73\n",
      "No. Observations:                 100   AIC:                             427.5\n",
      "Df Residuals:                      97   BIC:                             435.3\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0172      2.394     -0.007      0.994      -4.768       4.734\n",
      "x1             0.9503      0.213      4.466      0.000       0.528       1.373\n",
      "x2             2.2718      2.350      0.967      0.336      -2.392       6.936\n",
      "==============================================================================\n",
      "Omnibus:                        7.075   Durbin-Watson:                   1.790\n",
      "Prob(Omnibus):                  0.029   Jarque-Bera (JB):               12.153\n",
      "Skew:                           0.143   Prob(JB):                      0.00230\n",
      "Kurtosis:                       4.684   Cond. No.                         57.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print( intercept_model.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653c109",
   "metadata": {},
   "source": [
    "The intercept term is statistically equivalent to zero. The best fit value is quite small, so the intercept has barely any influence on the predictions. How can the R-squareds be so different?\n",
    "\n",
    "Check out: https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.RegressionResults.rsquared.html#statsmodels.regression.linear_model.RegressionResults.rsquared\n",
    "\n",
    "```\n",
    "This is defined here as 1 - ssr/centered_tss if the constant is included in the model and 1 - ssr/uncentered_tss if the constant is omitted.\n",
    "```\n",
    "TSS means Total Sum of Squares\n",
    "\n",
    "The centred_tss is\n",
    "sum (yi - yav)**2\n",
    "\n",
    "The uncentered_tss is (I assume)\n",
    "sum (yi)**2\n",
    "\n",
    "The second thing will be much bigger, since the output variables have a non-zero mean. This much bigger thing will divide the residual sum of squares and make it smaller, giving R squared much closer to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b2f60cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSR with intercept = 396.15194648356356\n",
      "SSR without intercept = 396.1521568856103\n"
     ]
    }
   ],
   "source": [
    "print(\"SSR with intercept =\", intercept_model.ssr )\n",
    "print(\"SSR without intercept =\", nointercept_model.ssr )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceeca13",
   "metadata": {},
   "source": [
    "The sum of squared residuals `sum (yi - predi)**2` can be compared between models and makes much more sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa891953",
   "metadata": {},
   "source": [
    "## An alternative, out of sample testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f3cb8",
   "metadata": {},
   "source": [
    "Comparing the SSR is not ideal. Among other things, the number depends on the number of absolute values of the output. So if we change its units it changes. The noce thing about Rsquared is that **good==1** is very intuitive. Could compare AIC and BIC, but same issue with interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8519c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e636ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nointercept_model = sm.OLS(z_train, X_train).fit()\n",
    "Xc_train= sm.add_constant(X_train)  #allows nonzero intercept\n",
    "intercept_model = sm.OLS(z_train, Xc_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14d6fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.217\n",
      "Model:                            OLS   Adj. R-squared:                  0.197\n",
      "Method:                 Least Squares   F-statistic:                     10.66\n",
      "Date:                Mon, 21 Aug 2023   Prob (F-statistic):           8.16e-05\n",
      "Time:                        08:33:58   Log-Likelihood:                -167.94\n",
      "No. Observations:                  80   AIC:                             341.9\n",
      "Df Residuals:                      77   BIC:                             349.0\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0639      2.541      0.419      0.677      -3.996       6.124\n",
      "x1             1.0538      0.230      4.582      0.000       0.596       1.512\n",
      "x2             0.7818      2.532      0.309      0.758      -4.261       5.825\n",
      "==============================================================================\n",
      "Omnibus:                        8.982   Durbin-Watson:                   1.553\n",
      "Prob(Omnibus):                  0.011   Jarque-Bera (JB):               16.916\n",
      "Skew:                           0.278   Prob(JB):                     0.000212\n",
      "Kurtosis:                       5.183   Cond. No.                         55.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.872\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.869\n",
      "Method:                 Least Squares   F-statistic:                              266.0\n",
      "Date:                Mon, 21 Aug 2023   Prob (F-statistic):                    1.47e-35\n",
      "Time:                        08:33:58   Log-Likelihood:                         -168.03\n",
      "No. Observations:                  80   AIC:                                      340.1\n",
      "Df Residuals:                      78   BIC:                                      344.8\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0750      0.223      4.817      0.000       0.631       1.519\n",
      "x2             1.7963      0.733      2.452      0.016       0.338       3.255\n",
      "==============================================================================\n",
      "Omnibus:                        9.874   Durbin-Watson:                   1.545\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               19.597\n",
      "Skew:                           0.314   Prob(JB):                     5.55e-05\n",
      "Kurtosis:                       5.342   Cond. No.                         11.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(intercept_model.summary())\n",
    "print(nointercept_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499c636",
   "metadata": {},
   "source": [
    "Note: the nointercept model is way better, as it should be, because it models the data using the right function! To compare the models with something like R-squared we can follow https://stats.stackexchange.com/questions/228540/how-to-calculate-out-of-sample-r-squared, see also https://arxiv.org/pdf/2302.05131.pdf\n",
    "\n",
    "We have some baseline for MSE which we compare to out of sample (OOS) predictions\n",
    "R_OSS = 1 - MSE_model / MSE_baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07a526fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_OSS(intercept) = 0.04886037975215063\n",
      "R_OSS(no_intercept) = 0.06731354353233754\n"
     ]
    }
   ],
   "source": [
    "zbar = np.mean(z)\n",
    "n_test = z_test.shape[0]\n",
    "TSS = (np.sum( (z_test - zbar)**2 )/(n_test-1))*( (n_test + 1)/n_test )\n",
    "TSS #this is Variance of the test set around the sample average times some scaling factor that probably doesn't matter\n",
    "\n",
    "\n",
    "nointercept_pred = nointercept_model.predict(X_test)\n",
    "Xc_test= sm.add_constant(X_test)  #allows nonzero intercept\n",
    "intercept_pred = intercept_model.predict(Xc_test)\n",
    "\n",
    "def MSE_OOS(pred):\n",
    "    return np.sum( (z_test - pred)**2 )/n_test\n",
    "\n",
    "print( \"R_OSS(intercept) =\", 1 - MSE_OOS(intercept_pred)/TSS )\n",
    "print( \"R_OSS(no_intercept) =\", 1 - MSE_OOS(nointercept_pred)/TSS )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbc14d",
   "metadata": {},
   "source": [
    "This means \n",
    "1. the no intercept model is a bit better than the intercept one.  \n",
    "2. The model, just barely, outperforms the benchmark model (predicting outputs based on the average value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a645b381",
   "metadata": {},
   "source": [
    "Let's do the same analysis with less noisy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f226fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.914\n",
      "Model:                            OLS   Adj. R-squared:                  0.912\n",
      "Method:                 Least Squares   F-statistic:                     411.6\n",
      "Date:                Mon, 21 Aug 2023   Prob (F-statistic):           7.74e-42\n",
      "Time:                        09:34:19   Log-Likelihood:                -20.792\n",
      "No. Observations:                  80   AIC:                             47.58\n",
      "Df Residuals:                      77   BIC:                             54.73\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9352      0.404      2.316      0.023       0.131       1.739\n",
      "x1             1.0380      0.037     28.399      0.000       0.965       1.111\n",
      "x2             0.9678      0.402      2.405      0.019       0.166       1.769\n",
      "==============================================================================\n",
      "Omnibus:                        5.929   Durbin-Watson:                   1.729\n",
      "Prob(Omnibus):                  0.052   Jarque-Bera (JB):                5.234\n",
      "Skew:                          -0.518   Prob(JB):                       0.0730\n",
      "Kurtosis:                       3.705   Cond. No.                         55.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "R-squared with intercept = 0.9144600643506104\n",
      "R-squared without intercept = 0.9960662055527627\n",
      "R_OSS(intercept) = 0.9084872866276139\n",
      "R_OSS(no_intercept) = 0.9070957634514216\n"
     ]
    }
   ],
   "source": [
    "##everythign in one cell!\n",
    "##make up some data\n",
    "z = x + 2*y + np.random.normal(0,0.3,100)\n",
    "X = np.vstack([x,y]).transpose()\n",
    "\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=12345)\n",
    "\n",
    "nointercept_model = sm.OLS(z_train, X_train).fit()\n",
    "Xc_train= sm.add_constant(X_train)  #allows nonzero intercept\n",
    "intercept_model = sm.OLS(z_train, Xc_train).fit()\n",
    "\n",
    "zbar = np.mean(z)\n",
    "n_test = z_test.shape[0]\n",
    "TSS = (np.sum( (z_test - zbar)**2 )/(n_test-1))*( (n_test + 1)/n_test )\n",
    "\n",
    "\n",
    "nointercept_pred = nointercept_model.predict(X_test)\n",
    "Xc_test= sm.add_constant(X_test)  #allows nonzero intercept\n",
    "intercept_pred = intercept_model.predict(Xc_test)\n",
    "\n",
    "def MSE_OOS(pred):\n",
    "    return np.sum( (z_test - pred)**2 )/n_test\n",
    "\n",
    "print(intercept_model.summary())\n",
    "print(\"R-squared with intercept =\", intercept_model.rsquared )\n",
    "print(\"R-squared without intercept =\", nointercept_model.rsquared )\n",
    "print( \"R_OSS(intercept) =\", 1 - MSE_OOS(intercept_pred)/TSS )\n",
    "print( \"R_OSS(no_intercept) =\", 1 - MSE_OOS(nointercept_pred)/TSS )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d6dd5",
   "metadata": {},
   "source": [
    "Note that these models do a **really** good job fitting the data. The R_OSS should be interpreted as the proportion of the null model's error/variance explained by the fitted model. In this case the null model is z_pred = mean(z). \n",
    "\n",
    "Rather than just 1 train test split, a K-fold cross validation would be more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3047edee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV R_OSS(intercept) = 0.9333484081555978\n",
      "5-fold CV R_OSS(nointercept) = 0.9321524642427595\n"
     ]
    }
   ],
   "source": [
    "z = x + 2*y + np.random.normal(0,0.3,100)\n",
    "X = np.vstack([x,y]).transpose()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "Ross_intercept = 0\n",
    "Ross_nointercept = 0\n",
    "for i, (train, test) in enumerate(kf.split(X)):\n",
    "\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    z_train, z_test = z[train], z[test]\n",
    "    \n",
    "    nointercept_model = sm.OLS(z_train, X_train).fit()\n",
    "    Xc_train= sm.add_constant(X_train)  #allows nonzero intercept\n",
    "    intercept_model = sm.OLS(z_train, Xc_train).fit()\n",
    "\n",
    "    zbar = np.mean(z)\n",
    "    n_test = z_test.shape[0]\n",
    "    TSS = (np.sum( (z_test - zbar)**2 )/(n_test-1))*( (n_test + 1)/n_test )\n",
    "\n",
    "\n",
    "    nointercept_pred = nointercept_model.predict(X_test)\n",
    "    Xc_test= sm.add_constant(X_test)  #allows nonzero intercept\n",
    "    intercept_pred = intercept_model.predict(Xc_test)\n",
    "\n",
    "    def MSE_OOS(pred):\n",
    "        return np.sum( (z_test - pred)**2 )/n_test\n",
    "\n",
    "    Ross_intercept += ( 1 - MSE_OOS(intercept_pred)/TSS )\n",
    "    Ross_nointercept += (1 - MSE_OOS(nointercept_pred)/TSS )\n",
    "\n",
    "Ross_intercept /= n_splits\n",
    "Ross_nointercept /= n_splits\n",
    "print( \"{}-fold CV R_OSS(intercept) =\".format(n_splits), Ross_intercept)\n",
    "print( \"{}-fold CV R_OSS(nointercept) =\".format(n_splits), Ross_nointercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad297c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
